# Transformer Architecture â€“ Simple Python Implementation

A clean, minimal **Python implementation** of the Transformer model from the paper **â€œAttention Is All You Need.â€**

This project includes:

* Self-Attention
* Multi-Head Attention
* Positional Embeddings
* Encoder & Decoder
* Full Transformer model

---

## ğŸ“„ File

```
transformer.py   # Entire Transformer implementation
```

---

## ğŸ“˜ References

1. [https://peterbloem.nl/blog/transformers](https://peterbloem.nl/blog/transformers)
   
---
